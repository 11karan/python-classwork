{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16547553-bf3f-4ccb-8387-48d426a3985c",
   "metadata": {},
   "source": [
    "# SVM ---> support vector machine\n",
    "It is supervised ml algo that is used for classicfication and regression task\n",
    "it is perticularly effective in dealing in complex and high demensional dataset\n",
    "the fundamental principle of svm is to find an optimal hyper plane that maximing seperates diff classes\n",
    "in the input space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48cc321-4ba1-4a6e-9d3e-a6d6b342c951",
   "metadata": {},
   "source": [
    "# HOW SVM WORKS\n",
    "1. we will prepare our dataset\n",
    "2. svm requires labeled training data consisting of input features and coressponding class labels\n",
    "3. each data point is reperesnted as an feature vector where each feature describe a particular characterstics of the data point\n",
    "4. the data points should be preprocessed and scaled to ensure the features aree on similiar scales btw 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d53eab-51ae-4871-9787-7b1a6b761b62",
   "metadata": {},
   "source": [
    "# HYPER PLANE AND MARGIN\n",
    "Svm aims to find a hyper plane that best seperates the diff classes in the feature space in an binary classicfication problem the hyper plane is an line in an tourist place or in an higher dimensional space.  \n",
    "Svm seeks to maximize the margin which is the distance btw the hyper plane and the nearest data points from each class.  \n",
    "The points on the margin are known as support vectors as they play an crucial role in defining the decision boundary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5dfd58-43a1-44f5-be67-29058191978d",
   "metadata": {},
   "source": [
    "# LINEAR SVM\n",
    "The linear svm finds an linear hoyper plane that seprate the classes the goal is to find the hyper plane that maximizes the margin while minizing the miss classification of training examples.\n",
    "Mathematicaly this can be formulated as an optimizing problem with the objective of minimizing the weights of the hyper plane subject to the constrainted tag all training examples lie on the correct side of the hyper plane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1b85f-af67-4623-a10e-41489ba70ab1",
   "metadata": {},
   "source": [
    "# NON-LINEAR SVM\n",
    "In cases where data is not linearly seperable  svm uses an techique called the kernel trick.  \n",
    "The kernel tricks makes the original input space into an higher dimensional feature space where the data point can be linearly separeable.  \n",
    "The choice of the kernel depends on the characterstics of the data and the problem at hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea2c3d-e4a3-4692-b84e-ea21fd2fd468",
   "metadata": {},
   "source": [
    "# TRAINING OF SVM\n",
    "Svm training involves finding the optimal hyper plane or decision boundary that seperates the classes.  \n",
    "the optimization problem is solved using methods such as quadratic programing or sqeuncial minimial optimzation.    \n",
    "The process involves solving for the weights of the hyper plane and the baised term which defines the decision boundary.  \n",
    "The objective is to miimize the regularization term while ensuring that training examples are correctly classified.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d57bf-cc96-4fb3-b3b6-4a950b837ae6",
   "metadata": {},
   "source": [
    "# Prediction of SVM\n",
    "once the svm model is trained itcan be used to predict the class labels of new unseen datapoints.  \n",
    "This algo computes the distance from the test point to the decision boundary.  \n",
    "The predicteed class label is determine based on which side of the decision boundary the point lies.  \n",
    "the decision function can also provide an confidence score or probability estimate for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7adad-21fd-42b5-8014-d505ed0b739c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
